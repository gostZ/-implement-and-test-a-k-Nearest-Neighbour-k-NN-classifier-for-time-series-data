{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assignment_1 - task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtw function, window = 4\n",
    "def dtw(s, t, window = 4):\n",
    "    n, m = len(s), len(t)\n",
    "    w = np.max([window, abs(n-m)]) # warping cannot be less than the difference in lengths. \n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    \n",
    "    for i in range(n+1):\n",
    "        for j in range(m+1):\n",
    "            dtw_matrix[i, j] = np.inf\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            dtw_matrix[i, j] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            cost = abs(s[i-1] - t[j-1])\n",
    "            # take last min from a square box\n",
    "            last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "    return dtw_matrix[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017644</td>\n",
       "      <td>0.030949</td>\n",
       "      <td>0.050555</td>\n",
       "      <td>0.044484</td>\n",
       "      <td>0.053277</td>\n",
       "      <td>0.041576</td>\n",
       "      <td>0.030947</td>\n",
       "      <td>0.027086</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024575</td>\n",
       "      <td>0.033780</td>\n",
       "      <td>0.026589</td>\n",
       "      <td>0.013932</td>\n",
       "      <td>0.024928</td>\n",
       "      <td>0.022589</td>\n",
       "      <td>0.038248</td>\n",
       "      <td>0.049838</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>0.040420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041296</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>0.040592</td>\n",
       "      <td>0.012190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060539</td>\n",
       "      <td>0.046991</td>\n",
       "      <td>0.023586</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>-0.002196</td>\n",
       "      <td>0.036730</td>\n",
       "      <td>0.039027</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.031440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>0.013283</td>\n",
       "      <td>0.029450</td>\n",
       "      <td>0.045201</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>0.018805</td>\n",
       "      <td>0.028901</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>0.039508</td>\n",
       "      <td>0.015171</td>\n",
       "      <td>0.034708</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.029502</td>\n",
       "      <td>0.040786</td>\n",
       "      <td>0.023144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>0.026653</td>\n",
       "      <td>0.038946</td>\n",
       "      <td>0.012494</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.032011</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.037448</td>\n",
       "      <td>0.044335</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.003624</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.015858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.036049</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.020628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.036653</td>\n",
       "      <td>0.018117</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.040599</td>\n",
       "      <td>0.016590</td>\n",
       "      <td>0.032730</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.011260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>0.017240</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.045530</td>\n",
       "      <td>0.046181</td>\n",
       "      <td>0.044288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015062</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.051677</td>\n",
       "      <td>0.036134</td>\n",
       "      <td>0.038030</td>\n",
       "      <td>0.047388</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.052691</td>\n",
       "      <td>0.051594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.042964</td>\n",
       "      <td>0.034519</td>\n",
       "      <td>-0.003426</td>\n",
       "      <td>-0.003353</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.041434</td>\n",
       "      <td>0.040670</td>\n",
       "      <td>0.034613</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.017716</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.047787</td>\n",
       "      <td>0.020318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.033658</td>\n",
       "      <td>0.038235</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.016061</td>\n",
       "      <td>0.026287</td>\n",
       "      <td>0.029979</td>\n",
       "      <td>0.024099</td>\n",
       "      <td>0.023647</td>\n",
       "      <td>0.017566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>0.022595</td>\n",
       "      <td>0.014942</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.019186</td>\n",
       "      <td>0.035905</td>\n",
       "      <td>0.031095</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.017948</td>\n",
       "      <td>-0.003614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.022805</td>\n",
       "      <td>0.020270</td>\n",
       "      <td>0.015546</td>\n",
       "      <td>0.038309</td>\n",
       "      <td>0.016303</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.018286</td>\n",
       "      <td>0.015730</td>\n",
       "      <td>0.007319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013016</td>\n",
       "      <td>0.030138</td>\n",
       "      <td>0.025736</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>0.050157</td>\n",
       "      <td>0.014435</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.036126</td>\n",
       "      <td>0.010751</td>\n",
       "      <td>-0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.012356</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.013149</td>\n",
       "      <td>0.047396</td>\n",
       "      <td>0.024340</td>\n",
       "      <td>0.017960</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.040015</td>\n",
       "      <td>-0.000449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014767</td>\n",
       "      <td>0.044482</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-0.003054</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.014849</td>\n",
       "      <td>0.031595</td>\n",
       "      <td>0.037902</td>\n",
       "      <td>0.008688</td>\n",
       "      <td>0.036395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6    \\\n",
       "0    1.0  0.017644  0.030949  0.050555  0.044484  0.053277  0.041576   \n",
       "1    1.0  0.041296  0.003551  0.027470  0.013158  0.009571  0.008074   \n",
       "2    1.0 -0.000720  0.013283  0.029450  0.045201  0.006317  0.018805   \n",
       "3    1.0  0.005201  0.013363  0.025733  0.026653  0.038946  0.012494   \n",
       "4    1.0  0.022926  0.027036  0.011668  0.019500  0.036049 -0.001297   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "139  3.0  0.008298  0.017240  0.010756  0.049488  0.005331  0.036829   \n",
       "140  3.0  0.004801  0.042964  0.034519 -0.003426 -0.003353  0.005231   \n",
       "141  3.0  0.033658  0.038235  0.009848  0.016061  0.026287  0.029979   \n",
       "142  3.0  0.022805  0.020270  0.015546  0.038309  0.016303  0.011456   \n",
       "143  3.0  0.012356  0.023970  0.013149  0.047396  0.024340  0.017960   \n",
       "\n",
       "          7         8         9    ...       141       142       143  \\\n",
       "0    0.030947  0.027086  0.013764  ...  0.024575  0.033780  0.026589   \n",
       "1    0.043743  0.040592  0.012190  ...  0.060539  0.046991  0.023586   \n",
       "2    0.028901  0.013832  0.015240  ...  0.016442  0.039508  0.015171   \n",
       "3    0.028303  0.032011  0.009467  ...  0.006383  0.037448  0.044335   \n",
       "4    0.019717  0.039583  0.020628  ...  0.026997  0.036653  0.018117   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "139  0.045530  0.046181  0.044288  ...  0.015062  0.028319  0.028443   \n",
       "140  0.002309  0.029905  0.011177  ...  0.017705  0.045264  0.041434   \n",
       "141  0.024099  0.023647  0.017566  ...  0.019306  0.022595  0.014942   \n",
       "142  0.018286  0.015730  0.007319  ...  0.013016  0.030138  0.025736   \n",
       "143  0.005501  0.040015 -0.000449  ...  0.014767  0.044482  0.000063   \n",
       "\n",
       "          144       145       146       147       148       149       150  \n",
       "0    0.013932  0.024928  0.022589  0.038248  0.049838  0.053419  0.040420  \n",
       "1    0.001562 -0.002196  0.036730  0.039027  0.007754  0.004697  0.031440  \n",
       "2    0.034708  0.010835  0.002942  0.006924  0.029502  0.040786  0.023144  \n",
       "3    0.011143 -0.003624  0.001467  0.020991  0.027675  0.001621  0.015858  \n",
       "4    0.018314  0.012536  0.040599  0.016590  0.032730  0.002498  0.011260  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "139  0.051677  0.036134  0.038030  0.047388  0.006875  0.052691  0.051594  \n",
       "140  0.040670  0.034613  0.001551  0.017716  0.001042  0.047787  0.020318  \n",
       "141  0.009259  0.019186  0.035905  0.031095  0.006592  0.017948 -0.003614  \n",
       "142  0.005955  0.050157  0.014435  0.005638  0.036126  0.010751 -0.005682  \n",
       "143 -0.003054  0.037014  0.014849  0.031595  0.037902  0.008688  0.036395  \n",
       "\n",
       "[144 rows x 151 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "umd = pd.read_csv(\"./UMD_TEST.txt\", sep=r\"\\s+\",header = None)\n",
    "umd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split feature_train, feature_test, label_train, label_test\n",
    "I use the same window and value of parameter (test_size and random_state) for train_test_split to make sure result of this task can compare with that of task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test:\n",
      " [3. 1. 2. 3. 2. 1. 3. 2. 2. 1. 2. 2. 2. 3. 3. 2. 1. 2. 3. 2. 1. 3. 3. 3.\n",
      " 2. 1. 1. 1. 1. 3. 1. 3. 1. 1. 1. 2. 3. 1. 3. 3. 3. 2. 1. 2. 1. 1. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "#create label\n",
    "label = []\n",
    "feature = []\n",
    "for i in range(len(umd)):\n",
    "    label.append(umd.values[i][0])  # true label\n",
    "    feature.append(umd.values[i][1:])\n",
    "\n",
    "label = np.array(label)\n",
    "feature = np.array(feature)\n",
    "\n",
    "    #Dataset partitioning\n",
    "    # parameters (feature value, target value); random_state is the random number seed\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature,label,test_size=0.33, random_state=42)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(feature,label)\n",
    "\n",
    "print(\"y_test:\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN classifier\n",
    "the knn_classifer function is a k-NN classifier. \n",
    "Parameter metric = dtw means this function use dtw function to calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifer(x_train, x_test, y_train, y_test,k):\n",
    "    \n",
    "    # KNN estimator\n",
    "    estimator = KNeighborsClassifier(n_neighbors = k, metric = dtw)\n",
    "    estimator.fit(x_train, y_train) #Put in the feature values of the training set and the target values for training\n",
    "    \n",
    "    # model evaluation\n",
    "    # method one: Direct comparison of true and predicted values\n",
    "    y_predict = estimator.predict(x_test)\n",
    "    print(\"y_predict:\\n\",y_predict)\n",
    "    print(\"y_test:\\n\",y_test)\n",
    "    print(\"comparing results:\\n\",y_test == y_predict)\n",
    "    \n",
    "    # method two: calculate accuracy\n",
    "    score = estimator.score(x_test, y_test)\n",
    "    print(\"accuray:\\n\",score)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict:\n",
      " [3. 1. 2. 3. 2. 1. 2. 2. 2. 1. 2. 2. 2. 3. 3. 2. 1. 2. 3. 2. 1. 3. 3. 1.\n",
      " 2. 1. 1. 1. 1. 3. 1. 3. 1. 1. 1. 2. 3. 1. 3. 3. 3. 2. 1. 2. 1. 1. 2. 1.]\n",
      "y_test:\n",
      " [3. 1. 2. 3. 2. 1. 3. 2. 2. 1. 2. 2. 2. 3. 3. 2. 1. 2. 3. 2. 1. 3. 3. 3.\n",
      " 2. 1. 1. 1. 1. 3. 1. 3. 1. 1. 1. 2. 3. 1. 3. 3. 3. 2. 1. 2. 1. 1. 2. 1.]\n",
      "comparing results:\n",
      " [ True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True]\n",
      "accuray:\n",
      " 0.9583333333333334\n",
      "run_time:\n",
      " 147.41625118255615 s\n"
     ]
    }
   ],
   "source": [
    "# performance\n",
    "start_time = time.time()\n",
    "knn_classifer(x_train, x_test, y_train, y_test,3) #k = 3\n",
    "end_time = time.time()\n",
    "print(\"run_time:\\n\",end_time - start_time,\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that the 1-NN results\n",
    "I set K = 1, and then compare this result with the result in task 1\n",
    "\n",
    "result in task 1 is:\n",
    "score of dtw: 0.9583333333333334 run_time is 90.58415198326111\n",
    "\n",
    "result in here is:\n",
    "accuray:0.9583333333333334 run_time: 140.84758806228638 s\n",
    "\n",
    "conclusion: successfully verify that the 1-NN results are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing with 1-NN:\n",
      "y_predict:\n",
      " [3. 1. 2. 3. 2. 1. 2. 2. 2. 1. 2. 2. 2. 3. 3. 2. 1. 2. 3. 2. 1. 3. 3. 3.\n",
      " 2. 1. 1. 1. 2. 3. 1. 3. 1. 1. 1. 2. 3. 1. 3. 3. 3. 2. 1. 2. 1. 1. 2. 1.]\n",
      "y_test:\n",
      " [3. 1. 2. 3. 2. 1. 3. 2. 2. 1. 2. 2. 2. 3. 3. 2. 1. 2. 3. 2. 1. 3. 3. 3.\n",
      " 2. 1. 1. 1. 1. 3. 1. 3. 1. 1. 1. 2. 3. 1. 3. 3. 3. 2. 1. 2. 1. 1. 2. 1.]\n",
      "comparing results:\n",
      " [ True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True]\n",
      "accuray:\n",
      " 0.9583333333333334\n",
      "run_time:\n",
      " 140.84758806228638 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"comparing with 1-NN:\")\n",
    "knn_classifer(x_train, x_test, y_train, y_test,1)\n",
    "end_time = time.time()\n",
    "print(\"run_time:\\n\",end_time - start_time,\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN - Euclidean ##\n",
    "the only difference between knn_classifer_euclidean function and knn_classifer is that metric in knn_classifer is dtw \n",
    "\n",
    "when k = 3, the accuracy and run time of k-NN-Euclidean is \n",
    "accuray:\n",
    " 0.9375\n",
    "run_time:\n",
    " 0.0189359188079834 s\n",
    " \n",
    "while the accuracy and run time of k-NN-dtw is\n",
    "accuray:\n",
    " 0.9583333333333334\n",
    "run_time:\n",
    " 147.41625118255615 s\n",
    " \n",
    "conclusion: the accurary of k-NN-dtw is better than that of euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifer_euclidean(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    #KNN estimator\n",
    "    estimator = KNeighborsClassifier(n_neighbors = 3)\n",
    "    estimator.fit(x_train, y_train) #Put in the feature values of the training set and the target values for training\n",
    "    \n",
    "    # model evaluation\n",
    "    # method one: Direct comparison of true and predicted values\n",
    "    y_predict = estimator.predict(x_test)\n",
    "    print(\"y_predict:\\n\",y_predict)\n",
    "    print(\"y_test:\\n\",y_test)\n",
    "    print(\"comparing results:\\n\",y_test == y_predict)\n",
    "    \n",
    "    # method two: accuracy\n",
    "    score = estimator.score(x_test, y_test)\n",
    "    print(\"accuray:\\n\",score)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict:\n",
      " [3. 1. 2. 3. 2. 1. 3. 2. 2. 1. 2. 2. 2. 2. 3. 2. 1. 2. 3. 2. 1. 3. 3. 3.\n",
      " 2. 1. 1. 1. 2. 3. 1. 3. 1. 1. 1. 2. 3. 1. 3. 3. 3. 2. 1. 2. 1. 2. 2. 1.]\n",
      "y_test:\n",
      " [3. 1. 2. 3. 2. 1. 3. 2. 2. 1. 2. 2. 2. 3. 3. 2. 1. 2. 3. 2. 1. 3. 3. 3.\n",
      " 2. 1. 1. 1. 1. 3. 1. 3. 1. 1. 1. 2. 3. 1. 3. 3. 3. 2. 1. 2. 1. 1. 2. 1.]\n",
      "comparing results:\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True]\n",
      "accuray:\n",
      " 0.9375\n",
      "run_time:\n",
      " 0.0189359188079834 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "knn_classifer_euclidean(x_train, x_test, y_train, y_test)\n",
    "end_time = time.time()\n",
    "print(\"run_time:\\n\",end_time - start_time,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
